{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d769ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8004b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, 0]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb63b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = metrics.mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = np.sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = np.sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38915edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "df=pd.read_csv('D:\\\\Ethereum project\\\\Data Processing\\\\5-original2016-43.csv', header=0, parse_dates=['Date'], index_col=['Date'])\n",
    "\n",
    "# starting time\n",
    "start = time.time()\n",
    "\n",
    "#start analysis data from 1/1/2018\n",
    "df=df.loc['2018-01-01':,:]\n",
    "\n",
    "# Perform Log Transformation\n",
    "df=np.log(df+1)\n",
    "\n",
    "n_input = 14\n",
    "n_out = 1\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0, 1))\n",
    "df_norm = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_norm.index=df.index\n",
    "\n",
    "# restructure into windows of weekly data\n",
    "train, test = df_norm.loc['2018-01-01':'2020-12-27'],  df_norm.loc['2020-12-28':'2021-05-30']\n",
    "\n",
    "train = array(split(train, len(train)/n_out))\n",
    "test = array(split(test, len(test)/n_out))\n",
    "\n",
    "train_index = df_norm.loc['2018-01-01':'2020-12-27'].index\n",
    "test_index = df_norm.loc['2020-12-28':'2021-05-30'].index\n",
    "y_train = train[:,:,0].reshape(train.shape[0]*train.shape[1]) \n",
    "\n",
    "\n",
    "# convert history into inputs and outputs\n",
    "# flatten data\n",
    "sequences = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "train_x, train_y= split_sequences(sequences, n_input, n_out)\n",
    "n_features = train_x.shape[2]\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "# Multi-headed MLP\n",
    "#--------------------------\n",
    "ModelType='Multi-headed MLP'\n",
    "# separate input data\n",
    "X=[train_x[:, :, i] for i in range(train_x.shape[2])]\n",
    "\n",
    "# first input model\n",
    "visible= [Input(shape=(n_input,)) for i in range(n_features)]\n",
    "dense=[Dense(50, activation='relu')(visible[i]) for i in range(n_features)]\n",
    "\n",
    "# merge input models\n",
    "merge = concatenate([dense[i] for i in range(train_x.shape[2])])\n",
    "output = Dense(n_out)(merge)\n",
    "model_mlp = Model(inputs=[visible[i] for i in range(train_x.shape[2])], outputs=output)\n",
    "model_mlp.compile(optimizer='Adam', loss='mse')\n",
    "# fit model\n",
    "model_mlp.fit(X, train_y, epochs=2000, verbose=0)\n",
    "\n",
    "#--------------------------\n",
    "# Vanilla LSTM\n",
    "#--------------------------\n",
    "\n",
    "model_vlstm = Sequential()\n",
    "model_vlstm.add(LSTM(50, activation='relu', input_shape=(n_input, n_features)))\n",
    "model_vlstm.add(Dense(n_out))\n",
    "model_vlstm.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model_vlstm.fit(train_x, train_y, epochs=200, verbose=0)\n",
    "\n",
    "#--------------------------\n",
    "# Stacked LSTM\n",
    "#--------------------------\n",
    "# define model\n",
    "model_slstm = Sequential()\n",
    "model_slstm.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_input,\n",
    "n_features)))\n",
    "model_slstm.add(LSTM(50, activation='relu'))\n",
    "model_slstm.add(Dense(n_out))\n",
    "model_slstm.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model_slstm.fit(train_x, train_y, epochs=200, verbose=0)\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "# Bidirectional LSTM\n",
    "#--------------------------\n",
    "# define model\n",
    "model_bdlstm = Sequential()\n",
    "model_bdlstm.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_input, n_features)))\n",
    "model_bdlstm.add(Dense(n_out))\n",
    "model_bdlstm.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model_bdlstm.fit(train_x, train_y, epochs=200, verbose=0)\n",
    "\n",
    "#--------------------------\n",
    "# Encoder-Decoder LSTM\n",
    "#--------------------------\n",
    "# define model\n",
    "model_edlstm = Sequential()\n",
    "model_edlstm.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\n",
    "model_edlstm.add(RepeatVector(n_out))\n",
    "model_edlstm.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model_edlstm.add(TimeDistributed(Dense(1)))\n",
    "model_edlstm.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model_edlstm.fit(train_x, train_y, epochs=200, verbose=0)\n",
    "\n",
    "\n",
    "# evaluate All model\n",
    "# history is a list of weekly data\n",
    "history = [x for x in train]\n",
    "Model_Names= [('mlp', 'Multi-Headed-MLP'), ('vlstm', 'Vanilla-LSTM'), ('slstm', 'Stacked-LSTM'), \n",
    "            ('bdlstm', 'Bi-Directional-LSTM'), ('edlstm', 'Encoder-Decoder-LSTM')]\n",
    "for m in Model_Names:\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        # flatten data\n",
    "        data = array(history)\n",
    "        data = data.reshape((data.shape[0] * data.shape[1] , data.shape[2]))\n",
    "        # retrieve last observations for input data\n",
    "        input_x = data[-n_input:, :]\n",
    "        # reshape into n input arrays\n",
    "        if ModelType= 'Multi-headed MLP':\n",
    "            input_x=[input_x[:, i].reshape((1, n_input)) for i in range(n_features)] \n",
    "        else:\n",
    "            input_x = input_x.reshape((1, n_input, n_features))\n",
    "        yhat = model.predict(input_x, verbose=0)\n",
    "        # we only want the vector forecast\n",
    "        yhat = yhat[0]\n",
    "        # store the predictions\n",
    "        predictions.append(yhat)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "    predictions = array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    \n",
    "\n",
    "\n",
    "    name='MLP Multivariate'\n",
    "# summarize_scores\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "\n",
    "#days = ['mon', 'tue', 'wed', 'thr', 'fri', 'sat', 'sun']\n",
    "#plt.plot(days, scores, marker='o', label='MLP')\n",
    "#plt.show()         \n",
    "\n",
    "# Plot normalized outputs\n",
    "#plt.plot(train_index, y_train, label='Training-norm')\n",
    "#plt.plot(test_index, predictions.reshape(predictions.shape[0]*predictions.shape[1]), label='Test Prediction-norm')\n",
    "#plt.plot(test_index, test[:, :, 0].reshape(test.shape[0]*test.shape[1]), label='Test Targets-norm')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "# Plot rescaled outputs\n",
    "    y_trainrev=(scaler.inverse_transform(train.reshape(train.shape[0]*train.shape[1],train.shape[2] ))[:,0])\n",
    "    y_testrev=(scaler.inverse_transform(test.reshape(test.shape[0]*test.shape[1],test.shape[2] ))[:,0])\n",
    "    y_predrev=(scaler.inverse_transform(np.concatenate((predictions.reshape(predictions.shape[0]*predictions.shape[1]).reshape(-1, 1), np.zeros((154,42))), axis=1))[:,0])\n",
    "\n",
    "    plt.figure(figsize=(16,8), dpi=100)\n",
    "    plt.plot(train_index, y_trainrev, label='Training')\n",
    "    plt.plot(test_index, y_predrev, label='Test Prediction')\n",
    "    plt.plot(test_index, y_testrev, label='Test Targets')\n",
    "    plt.gca().set(title='Prediction Using: Multi-Headed MLP ( Log Transformation, 1 Day Ahead) ', xlabel='Date', ylabel='Ether Price $')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # end time\n",
    "    end = time.time()\n",
    "\n",
    "    rmse = np.sqrt(np.mean((y_testrev-y_predrev)**2))\n",
    "    ape = np.mean(np.abs((y_testrev-y_predrev)*100/y_testrev))\n",
    "    print('Total RMSE is: ' , rmse)\n",
    "    print('Total APE is: ' , ape)\n",
    "    # total time taken\n",
    "    print(f\"Runtime of the program is {end - start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
